{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiqIi4H6iRHSR531afPXTQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uzmamushtaque/CSCI_4170_summer/blob/main/Lecture_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emdAMv5dEO9t"
      },
      "source": [
        "# Lecture 11\n",
        "\n",
        "# Today's Lecture\n",
        "\n",
        "1. More about CNN\n",
        "2. Case studies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjXXWpuSkD0J"
      },
      "source": [
        "# Classic Networks\n",
        "\n",
        "#LeNet-5\n",
        "\n",
        "LeNet was used in detecting handwritten cheques by banks based on MNIST dataset. Fully connected networks and activation functions were previously known in neural networks. LeNet-5 introduced convolutional and pooling layers. LeNet-5 is believed to be the base for all other ConvNets.\n",
        "\n",
        "\n",
        "[Source](https://www.kaggle.com/code/blurredmachine/lenet-architecture-a-complete-guide)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZH3Mtwp9iAa"
      },
      "source": [
        "# AlexNet\n",
        "\n",
        "introduced AlexNet, a deep convolutional neural network (CNN) that significantly improved image classification performance on the ImageNet dataset.\n",
        "\n",
        "**Key Contributions:**\n",
        "\n",
        "Deep Architecture: The model consists of eight layers, including five convolutional layers and three fully connected layers. It was significantly deeper than previous CNNs used for image classification.\n",
        "\n",
        "ReLU Activation: The paper popularized the Rectified Linear Unit (ReLU) as an activation function, which speeds up training compared to traditional activation functions like sigmoid or tanh.\n",
        "\n",
        "GPU Acceleration: The authors implemented parallel training using two GPUs, allowing them to train a much larger model efficiently.\n",
        "\n",
        "Dropout for Regularization: Introduced dropout in fully connected layers to reduce overfitting.\n",
        "\n",
        "Overlapping Max Pooling: Improved feature extraction and reduced the risk of overfitting compared to traditional non-overlapping pooling.\n",
        "\n",
        "Large-Scale Training on ImageNet: AlexNet was trained on 1.2 million images from ImageNet and achieved a top-5 error rate (the percentage of times a classification model fails to include the correct answer within its top five predicted possibilities), significantly outperforming the previous best model.\n",
        "\n",
        "Impact:\n",
        "AlexNet was a breakthrough in deep learning, proving that deep CNNs could achieve state-of-the-art results in image classification. It paved the way for more advanced architectures like VGG, GoogLeNet, and ResNet, influencing the rapid growth of deep learning in computer vision.\n",
        "\n",
        "AlexNet allows for multi-GPU training by putting half of the model's neurons on one GPU and the other half on another GPU. Not only does this mean that a bigger model can be trained, but it also cuts down on the training time.\n",
        "\n",
        "[Source](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7JpqGQ7MJsQ"
      },
      "source": [
        "# VGG-16\n",
        "\n",
        "VGG16 (also called OxfordNet) is a convolutional neural network architecture named after the Visual Geometry Group from Oxford, who developed it. It was used to win the ILSVR (ImageNet) competition in 2014.\n",
        "This paper proposed the VGG (Visual Geometry Group) architectures, including VGG16 and VGG19, which improved upon AlexNet by using small 3×3 convolutional filters stacked deeper, leading to better performance in image classification tasks.\n",
        "\n",
        "**Design Choices:**\n",
        "\n",
        "Deeper Networks: Prior networks (e.g., AlexNet) had around 8 layers; VGG networks go up to 16 (VGG16) or 19 (VGG19) layers.\n",
        "\n",
        "Small 3×3 Filters: Instead of using large convolutional kernels (e.g., 5×5 or 7×7), VGG stacks multiple 3×3 convolutions, which:\n",
        "\n",
        "\n",
        "1.   Capture complex patterns efficiently.\n",
        "2.   Reduce the number of parameters compared to larger filters.\n",
        "3.   Increase non-linearity, improving feature extraction.\n",
        "\n",
        "\n",
        "Uniform Architecture: Uses only 3×3 convolutions, 2×2 max pooling, and fully connected layers for simplicity and consistency.\n",
        "\n",
        "Increased Feature Maps: The depth is accompanied by an increase in the number of channels per layer (e.g., from 64 to 512).\n",
        "\n",
        "**VGG16 Structure:**\n",
        "13 convolutional layers (3×3 filters)\n",
        "5 max-pooling layers (2×2, stride 2)\n",
        "3 fully connected layers\n",
        "ReLU activations throughout\n",
        "Softmax classifier at the end\n",
        "\n",
        "**Training Details & Dataset**\n",
        "\n",
        "Dataset: Trained on ImageNet (ILSVRC-2014) with 1.2 million images across 1,000 categories.\n",
        "\n",
        "Data Augmentation: Includes random cropping, flipping, and color perturbations.\n",
        "Optimization: Uses Stochastic Gradient Descent (SGD) with momentum (0.9), weight decay (0.0005), and a gradually decreasing learning rate.\n",
        "\n",
        "Training Time: Due to depth, training takes 2–3 weeks on multiple GPUs.\n",
        "\n",
        "**Results & Performance**\n",
        "\n",
        "VGG16 achieves a top-5 error rate of 7.5%, improving upon previous architectures like AlexNet.\n",
        "\n",
        "Deeper models (VGG19) do not always perform better due to training challenges.\n",
        "Transfer Learning Impact: The pre-trained VGG models became widely used for feature extraction in various vision tasks (e.g., object detection, style transfer).\n",
        "\n",
        "**Impact & Legacy**\n",
        "\n",
        "VGG demonstrated that deeper networks with small filters improve accuracy.\n",
        "Inspired later architectures like ResNet, which tackled the issue of deeper networks through residual connections.\n",
        "Still used today for transfer learning despite being computationally expensive due to many parameters (~138 million in VGG16).\n",
        "\n",
        "[Source](https://gitea.sharpe6.com/Adog64/Adversarial-Machine-Learning-Clinic/raw/commit/0ba4e489bb77a0d2642923499598e309d8751435/references/Very_Deep_Convolutional_Networks_for_Large-Scale_Image_Recognition.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmLmp2c4MXPm"
      },
      "source": [
        "# ResNets\n",
        "\n",
        "ResNet, short for Residual Networks is a classic neural network used as a backbone for many computer vision tasks. This model was the winner of ImageNet challenge in 2015.\n",
        "\n",
        "Major issue posed to most deep networks is that of vanishing/exploding gradients. In image related tasks, there is an added issue of convergence(in a reasonable amount of time) due to complex loss surfaces.\n",
        "\n",
        "Consider an image of a dog standing on a square frame. Some features of this image require fewer layers of learning versus the intricate features that require a deeper network. Convergence will be unnecessarily slow when using a network with fixed depth across all paths to learn concepts (many of these can be learned by shallow networks).\n",
        "\n",
        "The skip connections provide a path of unimpeded gradient flow and therefore has important consequences for backpropagation algorithm. The skip connections create a situation where multiple paths of variable length exist from the input to the output. In such cases, the shortest paths enable the most learning and the longer ones can be viewed as residual contributions. This gives the learning algorithm the flexibility of choosing the appropriate level of non-linearity for a particular input(image).\n",
        "\n",
        "Inputs that an be classified with a small amount of non-linearity will skip many connections. Other inputs with a more complex structure might traverse a large number of connections in order to extract the relevant number of features.\n",
        "\n",
        "The approach is referred to as residual learning, in which learning along longer paths is like fine-tuning of the easier learning along shorter paths. this approach is well suited for tasks where different parts of the same image has different level of complexity.\n",
        "\n",
        "[Source](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp6RGpl3mwD4"
      },
      "source": [
        "# Inception\n",
        "\n",
        "GoogLeNet Architecture of Inception Network:\n",
        "This architecture has 22 layers in total. Using the dimension-reduced inception module, a neural network architecture is constructed. This is popularly known as GoogLeNet (Inception v1).\n",
        " There can be different levels of details that we need for different regions of an image and we do not know what is appropriate for each region upfront.\n",
        " An inception module deals with this issue by performing 3 different convolutions in parallel.\n",
        "\n",
        " Sometimes this may result in computational inefficiency because of large number of convolutions of different sizes. An efficient implementation involves use of 1 by 1 filters. The solution is to use a 1×1 filter to down sample the depth or number of feature maps.\n",
        "\n",
        "A 1×1 filter will only have a single parameter or weight for each channel in the input, and like the application of any filter results in a single output value. This structure allows the 1×1 filter to act like a single neuron with an input from the same position across each of the feature maps in the input. This single neuron can then be applied systematically with a stride of one, left-to-right and top-to-bottom without any need for padding, resulting in a feature map with the same width and height as the input.\n",
        "\n",
        "The 1×1 filter is so simple that it does not involve any neighboring pixels in the input; it may not be considered a convolutional operation. Instead, it is a linear weighting or projection of the input. Further, a nonlinearity is used as with other convolutional layers, allowing the projection to perform non-trivial computation on the input feature maps.\n",
        "\n",
        "[Source](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldVHcrDpr53k"
      },
      "source": [
        "# MobileNets\n",
        "\n",
        "MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used.\n",
        "\n",
        "[Source1](https://arxiv.org/pdf/1704.04861.pdf%EF%BC%89)\n",
        "\n",
        "[Source 2](https://openaccess.thecvf.com/content_cvpr_2018/papers/Sandler_MobileNetV2_Inverted_Residuals_CVPR_2018_paper.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0RHDwFUCSlS"
      },
      "source": [
        "# Transfer Learning\n",
        "\n",
        "Transfer learning has the benefit of decreasing the training time for a neural network model and can result in lower generalization error.\n",
        "\n",
        "The weights in re-used layers may be used as the starting point for the training process and adapted in response to the new problem. This usage treats transfer learning as a type of weight initialization scheme. This may be useful when the first related problem has a lot more labeled data than the problem of interest and the similarity in the structure of the problem may be useful in both contexts.\n",
        "\n",
        "[Source](https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/)\n",
        "\n",
        "[Data Augmentation Techniques](https://research.aimultiple.com/data-augmentation-techniques/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UUXc2CFnee7"
      },
      "source": [
        "# Introduction to Object Detection (Optional)\n",
        "\n",
        "[Article](https://huggingface.co/tasks/object-detection)\n",
        "\n",
        "[Implementation](https://www.tensorflow.org/hub/tutorials/object_detection)\n",
        "\n",
        "\n",
        "[Source](https://arxiv.org/pdf/1311.2524.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QabQHbBNlSyc"
      },
      "source": [
        "# Readings\n",
        "\n",
        "[Paper 1](https://ieeexplore.ieee.org/abstract/document/9687944)\n",
        "\n",
        "[Paper 2](https://link.springer.com/content/pdf/10.1186/s40537-021-00444-8.pdf)\n",
        "\n"
      ]
    }
  ]
}